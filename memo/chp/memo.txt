■サイト
https://www.kaggle.com/competitions/santander-customer-transaction-prediction/overview

■データセットの特徴
　・カラム数が多い　←　200
　・レコード数が多い　←　200000
　・各カラム内のばらつきが少ない
　・各カラム全体的に正規分布に従ってる
　・ターゲットカラムの値は2値　そのうち10％が「1」
　・
　・


■他の人の手法まとめ
●kaggler name
 Gabriel Preda
　
●処理の流れ
　1.Test＆train：行列数チェック
　2.Test＆train：ヘッドチェック
　3.Test＆train：欠損値の数、欠損値の存在割合、データ型チェック
　4.Test＆train：describeメソッドで統計量を表示
　5.Test＆train：トレーニングとテスト間の散布図プロット（各カラム）
　6.train：ターゲットカラムの値分布確認
　7.train：ターゲットを対象としたカーネル密度推定（ノンパラメトリック推定）
　8.Test＆train：トレーニングデータとテストデータを対象としたカーネル密度推定（ノンパラメトリック推定）
　9.Test＆train：行ごとの平均値の分布
 10.Test＆train：列ごとの平均値の分布
 11.Test＆train：行ごとの標準偏差の分布
 12.Test＆train：列ごとの標準偏差の分布
 13.train：ターゲットの値ごとにグループ化された、トレーニング データセットの行ごとの平均値の分布
 14.Test＆train：行ごとの最小値の分布
 15.Test＆train：列ごとの最小値の分布
 16.Test＆train：行ごとの最大値の分布
 17.Test＆train：列ごとの最大値の分布
 18.train：ターゲットの値 (0 と 1) ごとに分けた、トレーニング セットの行ごとの最小値の分布
 19.train：列ごとの最小値の分布

 他にもグラフ化していたがカット

 20.train：特徴間の相関（上位及び下位10個）
 21.train：重複する値の最大値の上位 15 個を表示
 22.特徴量エンジニアリング　（合計、平均、最大、最小、標準偏差、歪度、尖度、中央値）
  　各カラムの全レコードによって生成　　次元削減：200000x200　→　200X7
 23.対応するターゲット値の値ごとにグループ化された新しい機能の分布
 24.Test＆train：新しい特徴量の分布
 -モデル-
 25.train：IDとターゲットを削除
 26.モデルのハイパーパラメータの設定
 27.機能の重要度を確認
    　
●ポイント


●課題
・グラフプロットによって何を確認したかったか？
・アグリゲーションが有効だと判断できた根拠はなにか？
・LGBMを選択した理由は？そもそもなぜLGBMなのか？
　

●参考
https://www.kaggle.com/code/gpreda/santander-eda-and-prediction
https://zerebom.hatenablog.com/entry/2019/04/12/210322
https://club.informatix.co.jp/?p=1176